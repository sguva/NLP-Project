{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new environment and install dependencies.**\n",
    "\n",
    "Before running this notebook, create a environment and activate it.\n",
    "\n",
    "conda create -n nlp_project python=3.10 -y\n",
    "\n",
    "conda activate nlp_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: accelerate in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 1)) (0.25.0)\n",
      "Requirement already satisfied: bitsandbytes in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 2)) (0.41.3.post2)\n",
      "Collecting datasets (from -r requirements_pip.txt (line 3))\n",
      "  Using cached datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: huggingface-hub in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 4)) (0.19.4)\n",
      "Collecting matplotlib (from -r requirements_pip.txt (line 5))\n",
      "  Using cached matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting pandas (from -r requirements_pip.txt (line 6))\n",
      "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting peft (from -r requirements_pip.txt (line 7))\n",
      "  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 8)) (10.1.0)\n",
      "Requirement already satisfied: scikit-learn in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 9)) (1.3.2)\n",
      "Collecting tokenizers (from -r requirements_pip.txt (line 10))\n",
      "  Using cached tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 11)) (4.66.1)\n",
      "Collecting transformers (from -r requirements_pip.txt (line 12))\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting chardet (from -r requirements_pip.txt (line 13))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: charset-normalizer in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from -r requirements_pip.txt (line 14)) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: psutil in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from accelerate->-r requirements_pip.txt (line 1)) (0.4.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached pyarrow-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from datasets->-r requirements_pip.txt (line 3)) (2.31.0)\n",
      "Collecting xxhash (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: filelock in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from huggingface-hub->-r requirements_pip.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from huggingface-hub->-r requirements_pip.txt (line 4)) (4.9.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements_pip.txt (line 5))\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements_pip.txt (line 5))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements_pip.txt (line 5))\n",
      "  Using cached fonttools-4.46.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (156 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements_pip.txt (line 5))\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements_pip.txt (line 5))\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from matplotlib->-r requirements_pip.txt (line 5)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements_pip.txt (line 6))\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->-r requirements_pip.txt (line 6))\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from scikit-learn->-r requirements_pip.txt (line 9)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from scikit-learn->-r requirements_pip.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from scikit-learn->-r requirements_pip.txt (line 9)) (3.2.0)\n",
      "Collecting regex!=2019.12.17 (from transformers->-r requirements_pip.txt (line 12))\n",
      "  Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->-r requirements_pip.txt (line 3))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements_pip.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements_pip.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements_pip.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements_pip.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /sfs/weka/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirements_pip.txt (line 1)) (1.3.0)\n",
      "Using cached datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "Using cached matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached fonttools-4.46.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Using cached aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pyarrow-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.1 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, regex, pyparsing, pyarrow-hotfix, pyarrow, multidict, kiwisolver, fsspec, frozenlist, fonttools, dill, cycler, contourpy, chardet, attrs, async-timeout, yarl, pandas, multiprocess, matplotlib, aiosignal, tokenizers, aiohttp, transformers, peft, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 chardet-5.2.0 contourpy-1.2.0 cycler-0.12.1 datasets-2.15.0 dill-0.3.7 fonttools-4.46.0 frozenlist-1.4.0 fsspec-2023.10.0 kiwisolver-1.4.5 matplotlib-3.8.2 multidict-6.0.4 multiprocess-0.70.15 pandas-2.1.4 peft-0.7.1 pyarrow-14.0.1 pyarrow-hotfix-0.6 pyparsing-3.1.1 pytz-2023.3.post1 regex-2023.10.3 tokenizers-0.15.0 transformers-4.36.0 tzdata-2023.3 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install -r requirements_pip.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the toy version of COCO dataset and finetuned models (if required) from the following OneDrive: https://myuva-my.sharepoint.com/:f:/g/personal/efk7cz_virginia_edu/EjkxkVdrD1VEoDKaThUbd3EBb-G_dLQfh-x85DdOuCM3JA?e=4YXlJf \n",
    "\n",
    "Please note that the access is limited to anyone with URL can view and download within University of Virginia. \n",
    "\n",
    "Also, note that the non-LoRA finetuned versions of BLIP2 models are around 15GB each as in case of model fintuned using LoRA only the adapter weights are stored which is smaller in size when compared to the actual model weights. When we load the finetuned model, we first load the actual model (which is loaded from HF cache if already exists otherwise it'll download from the web and will cache it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set paths to dataset and saving temporary files.**\n",
    "\n",
    "Set CUDA_VISIBLE_DEVICES env variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_PATH=/scratch/efk7cz/NLP - Project/COCO 2017 NLP/\n",
      "env: SAVE_DIR=/scratch/efk7cz/nlp_project\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env DATASET_PATH=/scratch/efk7cz/NLP - Project/COCO 2017 NLP/\n",
    "%env SAVE_DIR=/scratch/efk7cz/nlp_project\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate training and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Working on train data_________________\n",
      "[{'image_id': 558840, 'bbox': [199.84, 200.46, 77.71, 70.88], 'category_id': 58}, {'image_id': 200365, 'bbox': [234.22, 317.11, 149.39, 38.55], 'category_id': 58}, {'image_id': 200365, 'bbox': [239.48, 347.87, 160.0, 57.81], 'category_id': 58}, {'image_id': 200365, 'bbox': [296.65, 388.33, 1.03, 0.0], 'category_id': 58}, {'image_id': 200365, 'bbox': [251.87, 333.42, 125.94, 22.71], 'category_id': 58}, {'image_id': 495357, 'bbox': [337.02, 244.46, 66.47, 66.75], 'category_id': 18}, {'image_id': 116061, 'bbox': [213.81, 192.39, 53.94, 70.28], 'category_id': 18}, {'image_id': 16164, 'bbox': [324.66, 247.92, 250.87, 181.02], 'category_id': 18}, {'image_id': 205350, 'bbox': [260.18, 252.76, 67.91, 53.3], 'category_id': 18}, {'image_id': 74, 'bbox': [61.87, 276.25, 296.42, 103.18], 'category_id': 18}]\n",
      "Time taken:  0.31240365902582806  minutes.\n",
      "Written 860001 annotations to file\n",
      "Done. Time taken:  0.4595642566680908  minutes.\n",
      "Written 201358 annotations to file\n",
      "Done. Time taken:  0.09404139121373495  minutes.\n",
      "Done. Time taken:  0.27907621463139853  minutes.\n",
      "Done. Time taken:  0.5838054339090983  minutes.\n",
      "558840 [('hot dog', 'middleCenter'), ('cup', 'middleLeft'), ('dining table', 'bottomLeft')]\n",
      "495357 [('dog', 'middleCenter'), ('motorcycle', 'middleCenter')]\n",
      "116061 [('dog', 'middleCenter'), ('handbag', 'middleLeft'), ('bottle', 'middleCenter')]\n",
      "16164 [('dog', 'bottomRight'), ('toilet', 'topLeft')]\n",
      "95899\n",
      "1302241 questions and answers generated.\n",
      "\n",
      "Questions and answers saved to /scratch/efk7cz/nlp_project/data_generation/generated_questions_and_answers_train.csv.\n",
      "\n",
      "___________Working on val data_________________\n",
      "[{'image_id': 289343, 'bbox': [473.07, 395.93, 38.65, 28.67], 'category_id': 18}, {'image_id': 61471, 'bbox': [272.1, 200.23, 151.97, 279.77], 'category_id': 18}, {'image_id': 472375, 'bbox': [124.71, 196.18, 372.85, 356.81], 'category_id': 18}, {'image_id': 520301, 'bbox': [112.71, 154.82, 367.29, 479.35], 'category_id': 18}, {'image_id': 579321, 'bbox': [200.61, 89.65, 400.22, 251.02], 'category_id': 18}, {'image_id': 494869, 'bbox': [0.0, 421.09, 154.53, 208.61], 'category_id': 18}, {'image_id': 554002, 'bbox': [427.58, 77.87, 188.88, 285.91], 'category_id': 18}, {'image_id': 78823, 'bbox': [197.97, 117.22, 170.45, 222.07], 'category_id': 18}, {'image_id': 419974, 'bbox': [61.68, 389.34, 130.77, 138.47], 'category_id': 18}, {'image_id': 404484, 'bbox': [86.93, 90.76, 82.5, 74.54], 'category_id': 18}]\n",
      "Time taken:  0.008570337295532226  minutes.\n",
      "Written 36781 annotations to file\n",
      "Done. Time taken:  0.013619458675384522  minutes.\n",
      "Written 8548 annotations to file\n",
      "Done. Time taken:  0.006101087729136149  minutes.\n",
      "Done. Time taken:  0.006168095270792643  minutes.\n",
      "Done. Time taken:  0.013556166489919027  minutes.\n",
      "289343 [('dog', 'middleRight'), ('person', 'middleCenter'), ('bench', 'bottomLeft'), ('bicycle', 'middleCenter')]\n",
      "61471 [('dog', 'bottomCenter'), ('bottle', 'topLeft'), ('toilet', 'topCenter')]\n",
      "472375 [('dog', 'middleCenter'), ('motorcycle', 'middleCenter')]\n",
      "520301 [('dog', 'middleCenter')]\n",
      "4109\n",
      "54874 questions and answers generated.\n",
      "\n",
      "Questions and answers saved to /scratch/efk7cz/nlp_project/data_generation/generated_questions_and_answers_val.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python gen_data_from_COCO.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the classification model.**\n",
    "\n",
    "Inputs: Image + object name (as text) | Output: Classification label\n",
    "\n",
    "We'll be using the ViltForQuestionAnswering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading train data dictionary............\n",
      "Len of dic: 171\n",
      "Encoding data: 100%|█████████████████████████| 171/171 [00:01<00:00, 130.27it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/classification/classification_train_-1.pth\n",
      "Done saving!\n",
      "Some weights of ViltForQuestionAnswering were not initialized from the model checkpoint at dandelin/vilt-b32-mlm and are newly initialized: ['classifier.1.bias', 'classifier.0.weight', 'classifier.1.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Training for 2 epochs.............\n",
      "Epoch 0: 100%|█████████████████████████| 6/6 [00:03<00:00,  1.51it/s, loss=5.56]\n",
      "Epoch 0, Loss: 6.0210206508636475\n",
      "Epoch 1: 100%|█████████████████████████| 6/6 [00:01<00:00,  3.69it/s, loss=4.61]\n",
      "Epoch 1, Loss: 4.95771853129069\n",
      "\n",
      " Saved the training verbose and training loss at /scratch/efk7cz/nlp_project/classification\n",
      "\n",
      "Saved model to disk after final epoch !\n",
      "Created HF pipeline and saved it as well.\n",
      "object_name: microwave\n",
      "prection: [{'score': 0.38649290800094604, 'answer': 'middleLeft'}]\n",
      "Actual location: middleCenter\n",
      "Total time taken: 0:00:41.511006\n"
     ]
    }
   ],
   "source": [
    "!python classification_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved classification model to run it on validation data and save the results to csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading dictionary............\n",
      "Len of dic: 19\n",
      "Dataset({\n",
      "    features: ['row_id', 'image_id', 'image_path', 'positionName', 'categoryName'],\n",
      "    num_rows: 19\n",
      "})\n",
      "Map: 100%|███████████████████████████████| 19/19 [00:01<00:00, 13.18 examples/s]\n",
      "Processed dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'question', 'answer'],\n",
      "    num_rows: 19\n",
      "})\n",
      "Running Inference::  32%|███████▌                | 6/19 [00:00<00:01,  7.82it/s]/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Running Inference:: 100%|███████████████████████| 19/19 [00:01<00:00, 14.66it/s]\n",
      "Validation Accuracy: 0.15789473684210525\n",
      "---------Saved the results at classification_results.csv-----------\n",
      "Total time taken: 0:00:09.051300\n"
     ]
    }
   ],
   "source": [
    "!python classification_val.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now moving onto Question-Answering model which generate answers.**\n",
    "\n",
    "Inputs: Image + Question (text) | Output: Generated Answer (text)\n",
    "\n",
    "We'll be finetuning the BLIP2 model using LoRA.\n",
    "\n",
    "The model itself take around 15GB on GPU, so make sure the GPU you are using has atleast 32GB of memory to run the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading train data dictionary............\n",
      "Len of dic: 1186\n",
      "Encoding image data: 100%|████████████████| 1186/1186 [00:01<00:00, 1175.21it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/answer_generation/answer_generation_train_-1.pth\n",
      "Done saving!\n",
      "\n",
      " Loading the model..........\n",
      "Downloading shards: 100%|███████████████████████| 8/8 [00:00<00:00, 3219.89it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:03<00:00,  2.01it/s]\n",
      "trainable params: 83,886,080 || all params: 3,828,566,016 || trainable%: 2.191057425924767\n",
      "\n",
      "Training for 2 epochs.........\n",
      "Epoch 0: 100%|██████████████████████| 38/38 [00:47<00:00,  1.25s/it, loss=0.764]\n",
      "Epoch 0, Loss: 2.523900082236842\n",
      "Epoch 1: 100%|███████████████████████| 38/38 [00:45<00:00,  1.19s/it, loss=0.58]\n",
      "Epoch 1, Loss: 0.5673057154605263\n",
      "Figure(1000x500)\n",
      "Saved model to disk after final epoch !!\n",
      "\n",
      "Inference check on sample idx:5\n",
      "Question: Locate the the bicycle within the image. Answer:\n",
      "Generated answer: The bicycle is located at the middleCenter of the image.\n",
      "Actual answer:    The bicycle is located at the middleLeft of the image.\n",
      "\n",
      "Total time taken: 0:02:58.643559\n"
     ]
    }
   ],
   "source": [
    "!python question_answer_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved QA model to run it on validation data and save the results to csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading val data dictionary............\n",
      "Len of dic: 112\n",
      "Encoding image data: 100%|██████████████████| 112/112 [00:00<00:00, 1012.96it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/answer_generation/answer_generation_val_-1.pth\n",
      "Done saving!\n",
      "\n",
      " Loading the model..........\n",
      "Downloading shards: 100%|███████████████████████| 8/8 [00:00<00:00, 1838.70it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "Running Inference:: 100%|█████████████████████| 112/112 [02:58<00:00,  1.59s/it]\n",
      "---------Saved the results at answer_generation_results.csv-----------\n",
      "Total time taken: 0:03:19.094545\n"
     ]
    }
   ],
   "source": [
    "!python question_answer_val.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For evaluation on the generated results, please check the intrinsic_evaluation.ipynb and extrinsic_evaluation.ipynb notebooks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Delete the SAVE_DIR and its contents****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $SAVE_DIR/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the initially set environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: -u=DATASET_PATH\n",
      "env: -u=SAVE_DIR\n"
     ]
    }
   ],
   "source": [
    "# Remove environment variables.\n",
    "%env -u DATASET_PATH\n",
    "%env -u SAVE_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
